{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091d155-be77-4bd6-9ff2-fb69afa41777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf \n",
    "import math\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Disable GPU usage for TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aea5dc-9b37-484f-8d92-6e8e53e50eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(422)\n",
    "tf.random.set_seed(422)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c3d17-758e-42d5-a499-d45729a8866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_filename(suffix_number, padding=5, prefix=\"img_\", extension=\"jpeg\"):\n",
    "    formatted_number = str(suffix_number).zfill(padding)\n",
    "    filename = f\"{prefix}{formatted_number}.{extension}\"\n",
    "    return filename\n",
    "\n",
    "def create_dir(directory_path, remove_if_exists=True):\n",
    "    # Supprimer le répertoire existant s'il existe\n",
    "    if os.path.exists(directory_path) and remove_if_exists:\n",
    "        shutil.rmtree(directory_path)\n",
    "\n",
    "    # Créer le nouveau répertoire\n",
    "    os.makedirs(directory_path, exist_ok=(not remove_if_exists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8348b5-f952-4ed2-8d7d-8b081ca0189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le répertoire racine\n",
    "\n",
    "root_path = \"../data/\"\n",
    "raw_path = os.path.join(root_path, 'raw')\n",
    "proc_path = os.path.join(root_path, 'proc')\n",
    "\n",
    "# Créer les répertoires train et test\n",
    "train_path = os.path.join(proc_path, \"train\")\n",
    "val_path = os.path.join(proc_path, \"val\")\n",
    "test_path = os.path.join(proc_path, \"test\")\n",
    "\n",
    "create_dir(train_path)\n",
    "create_dir(val_path)\n",
    "create_dir(test_path)\n",
    "\n",
    "# Liste des classes (yes, no)\n",
    "classes = [\"yes\", \"no\"]\n",
    "\n",
    "file_mapping = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "# Pour chaque classe\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(raw_path, class_name)\n",
    "    images = os.listdir(class_path)\n",
    "    \n",
    "    # Mélanger aléatoirement les images\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    # Calculer la séparation des données (60/20/20)\n",
    "    val_split_index = int(0.6 * len(images))\n",
    "    test_split_index = int(0.8 * len(images))\n",
    "    \n",
    "    # Diviser les données en ensembles d'entraînement et de test\n",
    "    train_images = images[:val_split_index]\n",
    "    val_images = images[val_split_index: test_split_index]\n",
    "    test_images = images[test_split_index:]\n",
    "    \n",
    "    # Créer les répertoires de classe dans les ensembles d'entraînement et de test\n",
    "    train_class_path = os.path.join(train_path, class_name)\n",
    "    val_class_path = os.path.join(val_path, class_name)\n",
    "    test_class_path = os.path.join(test_path, class_name)\n",
    "    \n",
    "    create_dir(train_class_path)\n",
    "    create_dir(val_class_path)\n",
    "    create_dir(test_class_path)\n",
    "\n",
    "\n",
    "    for dataset_name, dataset_images, dataset_class_path in [('train', train_images, train_class_path), \n",
    "                                                             ('val', val_images, val_class_path),\n",
    "                                                             ('test', test_images, test_class_path)]:\n",
    "        for image in dataset_images:\n",
    "            src = os.path.join(class_path, image)\n",
    "            dst = os.path.join(dataset_class_path, format_filename(counter))\n",
    "            shutil.copy(src, dst)\n",
    "            file_mapping += [{'raw_img_path': src, 'proc_img_path': dst, 'class_name': class_name, 'dataset_name': dataset_name}]\n",
    "            counter += 1\n",
    "\n",
    "df = pd.DataFrame.from_records(file_mapping)\n",
    "df.to_csv(os.path.join(root_path, 'file_mapping.csv'), index=False, header=True)\n",
    "df.groupby(['dataset_name', 'class_name']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ba99e-72df-404d-a1b7-4a82eaee2d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path_to_folder):\n",
    "    # Liste des classes (dossiers \"yes\" et \"no\")\n",
    "    classes = [\"yes\", \"no\"]\n",
    "    classes_enc = {'yes': 1, 'no': 0}\n",
    "\n",
    "    # Compter le nombre total d'images pour allouer les tableaux numpy\n",
    "    total_images = sum(len(os.listdir(os.path.join(path_to_folder, class_name))) for class_name in classes)\n",
    "\n",
    "    X = [None] * total_images  # Préallouer pour les images\n",
    "    y = [None] * total_images  # Préallouer pour les labels\n",
    "\n",
    "\n",
    "    last_index = 0\n",
    "    \n",
    "    # Parcourir chaque classe\n",
    "    for class_name in classes:\n",
    "        class_path = os.path.join(path_to_folder, class_name)\n",
    "\n",
    "        # Parcourir chaque image dans la classe\n",
    "        for idx, image_name in enumerate(os.listdir(class_path)):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "\n",
    "            # Lire l'image avec OpenCV\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # Ajouter l'image et le label aux tableaux X et y\n",
    "            X[last_index + idx] = image\n",
    "            y[last_index + idx] = classes_enc[class_name]\n",
    "\n",
    "        last_index = last_index + idx + 1\n",
    "\n",
    "    return np.array(X, dtype='object'), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9060f81-6eb7-4411-b674-8cb0c5e7eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_images(train_path)\n",
    "X_val, y_val = load_images(val_path)\n",
    "X_test, y_test = load_images(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be251392-d303-4121-b6e5-4bc6451bdbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(X, y, n):\n",
    "    # Filtrer les images par classe\n",
    "    yes_images =  X[y == 1][:n]\n",
    "    no_images = X[y == 0][:n]\n",
    "\n",
    "    # Calculer le nombre de lignes et colonnes pour chaque classe\n",
    "    n_rows = int(math.sqrt(n))\n",
    "    n_cols = math.ceil(n / n_rows)\n",
    "\n",
    "    # Créer la figure pour la classe \"yes\"\n",
    "    fig_yes, axs_yes = plt.subplots(n_rows, n_cols, figsize=(12, 10))\n",
    "    fig_yes.suptitle('Class: Yes')\n",
    "\n",
    "    # Afficher des images de la classe \"yes\"\n",
    "    for i in range(min(n, len(yes_images))):\n",
    "        axs_yes[i // n_cols, i % n_cols].imshow(yes_images[i])\n",
    "\n",
    "    # Créer la figure pour la classe \"no\"\n",
    "    fig_no, axs_no = plt.subplots(n_rows, n_cols, figsize=(12, 10))\n",
    "    fig_no.suptitle('Class: No')\n",
    "\n",
    "    # Afficher des images de la classe \"no\"\n",
    "    for i in range(min(n, len(no_images))):\n",
    "        axs_no[i // n_cols, i % n_cols].imshow(no_images[i])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f32bd28-5b11-4cdf-a023-33c8db976c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Utilisation de la fonction avec X et y provenant du train\n",
    "display_images(X_train, y_train, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92907e33-64ba-4b01-9c00-d3659fc29e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(X, target_size):\n",
    "    normalized_images = [None] * len(X)\n",
    "\n",
    "    for i, img in enumerate(X):\n",
    "        if len(img.shape) == 3:\n",
    "            # Convertir en niveaux de gris si c'est pas déjà le cas\n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Appliquer un filtre pour supprimer le bruit (par exemple, un filtre gaussien)\n",
    "        denoised_img = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "\n",
    "        # Détecter les contours pour trouver le crop optimal\n",
    "        _, thresh = cv2.threshold(denoised_img, 30, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if contours:\n",
    "            # Trouver le contour avec la plus grande aire\n",
    "            max_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            # Obtenir les coordonnées du rectangle englobant\n",
    "            x, y, w, h = cv2.boundingRect(max_contour)\n",
    "\n",
    "            # Cropper l'image pour obtenir la région d'intérêt\n",
    "            cropped_img = img[y:y+h, x:x+w]\n",
    "\n",
    "            # Redimensionner à target_size (pour s'assurer que toutes les images ont la même taille)\n",
    "            normalized_images[i] = cv2.resize(cropped_img, target_size, interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            # Redimensionner à target_size si aucun contour n'est détecté\n",
    "            normalized_images[i] = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return np.array(normalized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf8f53b-f0a4-4ee2-8592-e8a815cadcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de la fonction avec X (images non normalisées) et la taille cible\n",
    "target_size = (224, 224)\n",
    "X_train_norm = normalize_images(X_train, target_size)\n",
    "X_val_norm = normalize_images(X_val, target_size)\n",
    "X_test_norm = normalize_images(X_test, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c42379-148d-4ddb-9714-2829c1bb8951",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(X_train_norm, y_train, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f71b0a-0659-41c4-849e-2ca4c7a61ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle VGG-16 pré-entraîné (ne pas inclure la couche dense finale)\n",
    "base_model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "\n",
    "# figer les poids du VGG\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=RMSprop(lr=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Afficher la structure du modèle\n",
    "model.summary()\n",
    "\n",
    "# Créer un générateur d'images pour la data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.01,\n",
    "    height_shift_range=0.01,\n",
    "    zoom_range=0.05,\n",
    "    shear_range=0.01,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "# Ajuster le générateur aux données d'entraînement\n",
    "datagen.fit(X_train_norm)\n",
    "\n",
    "# Créer un callback d'arrêt anticipé\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Surveiller la perte sur l'ensemble de validation\n",
    "    patience=3,  # Arrêter l'entraînement si la perte ne diminue pas pendant 3 époques consécutives\n",
    "    restore_best_weights=True,  # Restaurer les poids du modèle aux meilleurs atteints pendant l'entraînement\n",
    "    verbose=1  # Afficher des messages lors de l'arrêt anticipé\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCH = 50\n",
    "\n",
    "# Entraîner le modèle avec l'augmentation de données\n",
    "history = model.fit(datagen.flow(X_train_norm, y_train, batch_size=BATCH_SIZE),\n",
    "                    epochs=EPOCH,\n",
    "                    steps_per_epoch=len(X_train_norm) // BATCH_SIZE,\n",
    "                    validation_data=(X_val_norm, y_val),\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "model.evaluate(X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a8d87-98c1-45f1-9ae6-c32403488f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43352f4b-d614-4935-af6f-6996ed3181ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model performance\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(1, len(history.epoch) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.yscale('log')\n",
    "plt.plot(epochs_range, acc, label='Train Set')\n",
    "plt.plot(epochs_range, val_acc, label='Val Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.yscale('log')\n",
    "plt.plot(epochs_range, loss, label='Train Set', )\n",
    "plt.plot(epochs_range, val_loss, label='Val Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d3a8b2-f0d8-4a2e-b2ff-7fb3e503a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc74e1-e598-42a8-bf29-45b048466974",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_prob > 0.5).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15423065-ff68-401d-b6fe-668573d662b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644056d0-0a83-4fcb-accb-4c47715ed349",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affec31e-99ac-44e5-abfd-82c3203a5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_ok_y_test = y_test[y_pred != y_test]\n",
    "not_ok_X_test = X_test[y_pred != y_test]\n",
    "\n",
    "display_images(not_ok_X_test, not_ok_y_test, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c84886-0fd2-461f-a8a7-8ac2bdeb0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, roc_auc_score, roc_curve\n",
    "\n",
    "print('recall = ', recall_score(y_test, y_pred))\n",
    "print('precision = ', precision_score(y_test, y_pred))\n",
    "print('f1 score = ', f1_score(y_test, y_pred))\n",
    "print('rocauc = ', roc_auc_score(y_test, y_pred_prob))\n",
    "\n",
    "# Calculate ROC curve metrics\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2, label='Random')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2337b0-b351-4adb-83d6-1c9dcb5e5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77f6a7-3cec-4e5d-ad54-466be7bd3fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_tumeur.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1992db4a-5a5a-493e-bb1b-85fc78239c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from config import MLFLOW_SERVER\n",
    "\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_SERVER)\n",
    "\n",
    "params = {\n",
    "    'batch_size' : BATCH_SIZE,\n",
    "    'epoch' : EPOCH\n",
    "}\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"MLflow Neuroguard\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    mlflow.log_metric(\"recall\", recall_score(y_test, y_pred))\n",
    "    mlflow.log_metric(\"precision\", precision_score(y_test, y_pred))\n",
    "    mlflow.log_metric(\"f1 score\", f1_score(y_test, y_pred) )\n",
    "    mlflow.log_metric(\"rocauc\", roc_auc_score(y_test, y_pred_prob) )\n",
    "\n",
    "    # # Log the model\n",
    "    mlflow.tensorflow.log_model(model, artifact_path='Neuroguard')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_cv",
   "language": "python",
   "name": "env_cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
